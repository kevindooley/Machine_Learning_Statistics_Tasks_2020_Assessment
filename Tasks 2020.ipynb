{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Machine Learning and Statistics Tasks 2020</h1>\n",
    "\n",
    "<h4 align=\"center\">By Kevin Dooley</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Task 1 - Square Root of 2\n",
    "\n",
    "This task is to write a Python function called $sqrt2$ that calculates and prints to the screen the square root of 2 to 100 decimal places. Contained in this jupyter notebook is research into the topic, a desciption of the algorithm and all relevant references. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction & Research\n",
    "\n",
    "A number is defined as an irrational number when it cannot be given as the ration of two integers. One of the most famous irrational numbers is the $\\sqrt2$. It can be proven that the $\\sqrt2$ is irrational through a proof by contradiction and assuming that the $\\sqrt2$ is rational. [1]\n",
    "\n",
    "From my research there any many different methods which will compute the square root of a number. I decided to use Newtons method. Newton's Method is a very familiar method and suitable for programmatic calculation [2]\n",
    "\n",
    "Newton's method which is also known as Newton-Raphson method is a root-finding algorithm that produces successively better approximations of the roots of a real-valued function. [3] If you have a function $f(x)=0$ and $x_0$ is close to the root of a number, then newthon's method for a derivation formula should mean the $x_1$ would give a better approximation of that root.\n",
    "\n",
    "To find the square root using Newton's method, you guess a solution $x_0$ of the equation $f(x)=0$. As a result, you will find the linear approximation of $f(x)=0$ at $x_0$ and be able to find $x$ intercept of the linear approximation. [6]\n",
    "\n",
    "As mentioned above, assuming $x_0$ is close to the solution of $f(x)=0$ you will find the approximation of $f(x)=0$ by the tangent line at $x_0$ and determine the $x$ intercept of the tangent line. You then determine the next approximation of the formula $x_1=x_0-\\frac{f(x_0)}{f'(x_0)}$. This is an iterative process in which you keeping determining the next $x$ intercept. The iterative process using the formula $x_n+1=x_0-\\frac{f(x_0)}{f'(x_0)}$ will give you the approximate root. Depending on how many times the iterative process is completed will determine the accuracy of the approximate result. [7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python function of $\\sqrt2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951454746218587388284504413604736328125000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "#Example of sqrt(2) \n",
    "# https://stackoverflow.com/questions/20811208/newton-s-method-for-finding-square-roots-in-python [8]\n",
    "\n",
    "def sqrt(n): #create a function called sqrt()\n",
    "    approx = n / 2.0 # the approx/first guess is X0\n",
    "    while True: # while condition is true\n",
    "        better = (approx + n / approx) / 2.0 # to get the better/x1 point\n",
    "        if abs(approx - better) < 0.00001: # if the absolute value (gives positive value if negative)of  x0 - x1 is < 0.00001 then return x1 (better). This would then interate through for x1-x2 <0.00001 etc until no longer true\n",
    "            return better\n",
    "        approx = better\n",
    "n=2**(0.5) #  input is square root of 2\n",
    "result = format(n, ',.100f') # formats to 100 decimal places. Need to solve '0' issue\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code can be verified to be correct using built in python functions $math$ and $sqrt$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623746899"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The verification step above demonstrates that the code in In[1] working as intended and finding the square root of 2. As can be seen from the output, the result does output 100 decimal places but the final 47 digits are showing as 0. This is because on most machines today, floats are approximated using a binary fraction with the numerator using the first 53 bits starting with the most significant bit and with the denominator as a power of two. [9] Normally, up to 53 digits precision would be fine, because that is more digits than most people find useful. It would be common where people may not even need more than 1 decimal point therefore Python keeps the number of digits manageable by displaying a rounded value. Python has limitations to completing this task because of the 53 digit precision. We have been asked to determine the square root of 2 to 100 decimal places. \n",
    "\n",
    "A way to address python's floating point precision issue, the input number needs to be increased and then determine an accurate approximate square root result for that number. It then must be divided down accordingly to show the correct answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730950488016887242096980785696718753769480731766797379907324784621070388503875343276415727\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/64278117/is-there-a-way-to-create-more-decimal-points-on-python-without-importing-a-libra\n",
    "# need to make starting number bigger so python can handle it\n",
    "#appropiately divide it back down at the end\n",
    "x = 2 * 10 ** 200\n",
    "\n",
    "r = x\n",
    "\n",
    "def test_diffs(x, r):\n",
    "    d0 = abs(x - r**2)\n",
    "    dm = abs(x - (r-1)**2)\n",
    "    dp = abs(x - (r+1)**2)\n",
    "    minimised = d0 <= dm and d0 <= dp\n",
    "    below_min = dp < dm\n",
    "    return minimised, below_min\n",
    "\n",
    "while True:\n",
    "    oldr = r\n",
    "    r = (r + x // r) // 2\n",
    "\n",
    "    minimised, below_min = test_diffs(x, r)\n",
    "    if minimised:\n",
    "        break\n",
    "\n",
    "    if r == oldr:\n",
    "        if below_min:\n",
    "            r += 1\n",
    "        else:\n",
    "            r -= 1\n",
    "        minimised, _ = test_diffs(x, r)\n",
    "        if minimised:\n",
    "            break\n",
    "\n",
    "print(f'{r // 10**100}.{r % 10**100:0100d}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. McLoughlin, I., The Square Root of 2. The Square Root of 2, [Online]. 1, 1. Available at: https://learnonline.gmit.ie/course/view.php?id=1121 [Accessed 6 October 2020]\n",
    "2. Wikipedia. Methods of computing square roots. [ONLINE] Available at: https://en.wikipedia.org/wiki/Methods_of_computing_square_roots. [Accessed 17 November 2020].\n",
    "3. Medium. How to Calculate the Square Root of a Number? — Newton-Raphson Method. [ONLINE] Available at: https://surajregmi.medium.com/how-to-calculate-the-square-root-of-a-number-newton-raphson-method-f8007714f64. [Accessed 17 November 2020].\n",
    "4. Math.ubc.ca. LaTeX. [ONLINE] Available at: https://www.math.ubc.ca/~pwalls/math-python/jupyter/latex/. [Accessed 17 November 2020].\n",
    "5. Github.com. markdown-preview-plus. [ONLINE] Available at: https://github.com/atom-community/markdown-preview-plus/issues/19. [Accessed 17 November 2020].\n",
    "6. Math.ubc.ca. Newton's Method. [ONLINE] Available at: https://www.math.ubc.ca/~pwalls/math-python/roots-optimization/newton/. [Accessed 17 November 2020].\n",
    "7. Math24.net. Newton's Method. [ONLINE] Available at: https://www.math24.net/newtons-method/. [Accessed 17 November 2020].\n",
    "8. Stackoverflow.com. Newton’s method for finding square roots in python. [ONLINE] Available at: https://stackoverflow.com/questions/20811208/newton-s-method-for-finding-square-roots-in-python. [Accessed 17 November 2020].\n",
    "9. Python.org. Floating Point Arithmetic: Issues and Limitations. [ONLINE] Available at: https://docs.python.org/3.4/tutorial/floatingpoint.html#floating-point-arithmetic-issues-and-limitations. [Accessed 17 November 2020]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Task 2 - Chi-squared Test\n",
    "\n",
    "This task is to analyse whether two categorical variables are independent using the Chi-squared  test  for  independence. Using the module package scipy.stats, verify that the Chi-squared value of 24.6 is correct and calculate the associated $p$ value for the example shown on the wikipedia page of the Chi-squared test.\n",
    "![Chi-squared](images/wiki.PNG)\n",

    "\n",
    "The question asks whether two categorical variables are independent of each other. Making that the null hypothesis as it is the statement being asked in a test of statistical significance.\n",
    "\n",
    "$H_0$ - if each person's neighborhood of residence is **independent** of the person's occupational classification.\n",
    "\n",
    "$H_1$ - if each person's neighborhood of residence is **dependent** of the person's occupational classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction & Research\n",
    "\n",
    "A chi-squared test, also written as $\\chi^2$ test, is a statistical hypothesis test that is valid to perform when the test statistic is chi-squared distributed under the null hypothesis. A well know variant of the Chi-squared test is Pearson's chi-squared test which is used to determine if there is a statistically significant difference between the expected frequencies and the observed frequencies in one or more categories of a contingency table.[1] In other words, chi-square test for independence compares two variables in a contingency table to see if they are related and it tests to see whether distributions of categorical variables differ from each another.\n",
    "\n",
    "Categorical variables are non-numerical and a Chi-squared statistic is a way to show a relationship between two categorical variables meaning it is appropiate for this task because the variables are neighbourhood and occupation (categorical).[2] \n",
    "\n",
    "There is no defining number that will indicate whether a chi-square test statistic is large enough to indicate a statistically significant difference or not. In general terms, you can compare your Chi-squared value to the critical value from a Chi-squared table or using the $p$ value. [2][3]\n",
    "\n",
    "If the Chi-squared value you calculated is higher than the critical value, you can assume the data does not fit the model (null hypothesis) and you reject the null hypothesis. If the Chi-squared value is less than the critical value, the data did fit the model and you fail to reject the null hypothesis. [2][3]\n",
    "\n",
    "It is also possible to determine if the difference is significant or not by using the $p$ value of which the Chi-squared test will give you. To determine the $p$ value you require the degrees of freedom `(calculate from (row - 1)(column - 1)` to determine from a contingency table)[4] and the $\\alpha$ value usually 0.05 (5%).[2][3] \n",
    "In this question,if the $p$ value is < 0.05, you reject the null hypothesis and the variables are determined to be dependent. \n",
    "If the $p$ value > 0.05, you fail to reject the null hypothesis and the variables are determined to be independent.[5]\n",
    "\n",
    "The below is the formula for calculating the chi-square. The python package scipy completes this formula for us effortlessly but basically what is does is:\n",
    "\n",
    "1. Every observed number in table, subtract the corresponding expected number [$O - E$]\n",
    "2. Square the difference [ $(O —E)^2$ ].\n",
    "3. Divide the squares obtained for each cell in the table by the expected number for that cell [ $\\frac{(O - E)^2}{E} $].\n",
    "4. Sum all the values for [ $\\frac{(O - E)^2}{E} $]. This is the chi square statistic. [7]\n",
    "\n",
    "![Chi-squared](images/chi.PNG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-squared test\n",
    "# reference https://towardsdatascience.com/running-chi-square-tests-in-python-with-die-roll-data-b9903817c51b\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "A_WC = [90,60,104,95]\n",
    "A_BC = [30,50,51,20]\n",
    "A_NC = [30,40,45,35]\n",
    "\n",
    "\n",
    "contingency_table = np.array([A_WC,A_BC,A_NC]) #create array with inputs stated on wikipedia\n",
    "#contingency_table - show table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.5712028585826,\n",
       " 0.0004098425861096696,\n",
       " 6,\n",
       " array([[ 80.53846154,  80.53846154, 107.38461538,  80.53846154],\n",
       "        [ 34.84615385,  34.84615385,  46.46153846,  34.84615385],\n",
       "        [ 34.61538462,  34.61538462,  46.15384615,  34.61538462]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html\n",
    "# import scipy \n",
    "from scipy import stats\n",
    "\n",
    "stats.chi2_contingency(contingency_table) # shows the Chi-squared result, p value and dof & expected result for each number/cell but difficult to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Chi2 Value===\n",
      "24.6\n",
      "\n",
      "\n",
      "===Degrees of Freedom===\n",
      "6\n",
      "\n",
      "\n",
      "===P-Value===\n",
      "0.0004098425861096696\n",
      "\n",
      "\n",
      "===Expected Values Contingency Table===\n",
      "[[ 80.53846154  80.53846154 107.38461538  80.53846154]\n",
      " [ 34.84615385  34.84615385  46.46153846  34.84615385]\n",
      " [ 34.61538462  34.61538462  46.15384615  34.61538462]]\n"
     ]
    }
   ],
   "source": [
    "# python allows this notation for variables\n",
    "# 4 variables\n",
    "# https://towardsdatascience.com/running-chi-square-tests-in-python-with-die-roll-data-b9903817c51b\n",
    "chi2_val, p_val, dof, table = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"===Chi2 Value===\")\n",
    "format_chi2 = \"{:.1f}\".format(chi2_val) #format to 1 decimal point as per wikipedia\n",
    "print(format_chi2)\n",
    "print(\"\\n\") # blank line between \n",
    "print(\"===Degrees of Freedom===\")\n",
    "print(dof)\n",
    "print(\"\\n\")\n",
    "print(\"===P-Value===\")\n",
    "print(p_val)\n",
    "print(\"\\n\")\n",
    "print(\"===Expected Values Contingency Table===\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null hypothesis is rejected, variables are dependent\n"
     ]
    }
   ],
   "source": [
    "#check if dependent or independent using p value \n",
    "# if and else statements to compare p_val to 0.05\n",
    "if p_val < 0.05:\n",
    "    print(\"Null hypothesis is rejected, variables are dependent\")\n",
    "else:\n",
    "    if p_val> 0.05:\n",
    "        print(\"Failed to reject null hypothesis, variables are independent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above you can also determine if dependent/independent using the critical value. From my research, I found the critical value to be 12.59 at a degree of freedom of 6. This critical value is less than the Chi-squared value of 24.7 meaning we reject the null hypothesis that the variables are independent of each other. [3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The results of the above calculations show that $\\chi2$ = 24.6 which is the same as the result on Wikipedia. Albeit not asked in the question, the degree of freedom is 6 which also matches with Wikipedia\n",
    "The $p$ value was determined to be 0.0004098425861096696.\n",
    "\n",
    "Based on results above, it can be determined that the variables neighbourhood and occupation are in fact dependent of each other and not independent. This can be concluded because the null hypothesis was if each person's neighborhood of residence is independent of the person's occupational classification. Because the chi-square value was higher than the critical value and also the $p$ value was below $a$ = 0.05 we reject the null hypothesis and as a result conclude that $H_1$ is true and that there is a relationship between the two categorical variables neighbourhood and occupation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Wikipedia. Chi-squared test - Wikipedia. [ONLINE] Available at: https://en.wikipedia.org/wiki/Chi-squared_test. [Accessed 18 November 2020].\n",
    "2. Statistics How To. Chi-Square Statistic: How to Calculate It / Distribution - Statistics How To. [ONLINE] Available at: https://www.statisticshowto.com/probability-and-statistics/chi-square/. [Accessed 18 November 2020].\n",
    "3. Chi-square (adv). Chi-square (adv). [ONLINE] Available at: https://mathbench.umd.edu/modules/statistical-tests_chisquare_advanced/page14.htm#:~:text=So%20for%20a%20test%20with,to%20reject%20the%20null%20hypothesis.. [Accessed 18 November 2020].\n",
    "4. Contingency Tables. Contingency Tables. [ONLINE] Available at: http://onlinestatbook.com/2/chi_square/contingency.html#:~:text=The%20degrees%20of%20freedom%20is,4%2D1)%20%3D%203.&text=Therefore%2C%20the%20sum%20of%20all,of%20subjects%20in%20the%20experiment.. [Accessed 18 November 2020].\n",
    "5. Chi-Square Test. Chi-Square Test. [ONLINE] Available at: https://www.mathsisfun.com/data/chi-square-test.html. [Accessed 18 November 2020].\n",
    "6. scipy.stats.chi2_contingency — SciPy v1.5.4 Reference Guide. 2020. scipy.stats.chi2_contingency — SciPy v1.5.4 Reference Guide. [ONLINE] Available at: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html. [Accessed 18 November 2020].\n",
    "7. Chi Square Statistics. Chi Square Statistics. [ONLINE] Available at: https://math.hws.edu/javamath/ryan/ChiSquare.html#:~:text=Calculate%20the%20chi%20square%20statistic,E)2%20%2F%20E%20%5D.. [Accessed 18 November 2020]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Task 3 - Standard Deviation \n",
    "\n",
    "The standard deviation of an array of numbers x is calculated using numpy as `np.sqrt(np.sum((x - np.mean(x))**2)/len(x))`\n",
    "Microsoft Excel has two different versions of the standard deviation calculation, STDEV.P and STDEV.S. STDEV.P functions performs the above calculation but in the STDEV.P calculation, the division is by len(x)-1 rather than len(x).\n",
    "Reserach both excel functions explaning the difference between them. Then use numpy to perform a simulation demonstrating that the STDEV.S calculaion is a better estimate for the standard deviation of a population when performed on a sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction & Research\n",
    "\n",
    "Standard deviation is a measure of the amount of variation or disersion of a set of values. A low standard deviation indicates that the values in the set tend to be close to the mean whereas a high standard deviation indicates that the values are further away fom the mean and spread out out over a wider range. The standard deviation is calculated as the square root of variance by determining each data point's deviation relative to the mean. [1]\n",
    "\n",
    "The standard deviation is denoted by the Greek symbol $\\sigma$ (sigma) for the population standard deviation and the Latin letter $s$ for the sample standard deviation. The standard deviation has a huge number of applications, it it used particulary in the financial sector where standard deviations of price data are frequently used as a measure of volatility and predict performance trends. [2].\n",
    "\n",
    "STDEV.P and STDEV.S are both excel functions for calculating the standard deviation of a set of values. STDEV.P calculates standard deviation based on the entire population given while STDEV.S estimates the standard deviation based on a sample, but STDEV.S assumes the given arguements are are a sample of a population[3][4]. STDEV.S can be used to partially correct sample bias. These two standard deviations - sample and population standard deviations - are calculated differently. \n",
    "\n",
    "As mentioned above, the standard deviation is a measure of how much variance there is in a set of numbers compared to the average (mean) of the numbers. STDEV.S uses `n − 1` instead of `n` in the formula for the sample variance and sample standard deviation where `n` is the number of observations in a sample. This is called Bessels correction and it corrects the bias in the estimation of the population variance and partially corrects the bias in the estimation of the population standard deviation. The reason the `n-1` only partially corrects bias for the estimation of the standard deviation is because the sample variance is an unbiased estimator of the population variance (remember standard deviation is the measure of variance)but its square root, the sample standard deviation, is a biased estimate of the population standard deviation; because the square root is a concave function. [7]\n",
    "\n",
    "Bessel's correction can provide a better estimation of the standard deviation when working with sample population. \n",
    "STDEV.P does not use Bessel's correction and STDEV.S does include it. Confusion can often arise as to which standard deviation function to use due to the names. STDEV.S (sample standard deviation) could be incorrectly interpreted as meaning the standard deviation of the smaller sample itself and not the estimate of the population standard deviation based on the sample. It is important to know the difference.[6]\n",
    "\n",
    "#### Formulas and Calculation\n",
    "\n",
    "**Population standard deviation:**\n",
    "\n",
    "$$\\sigma=\\sqrt\\frac{\\sum(x_i-\\mu)^2}{N}$$\n",
    "\n",
    "1. Calculate the mean ($\\mu$) of all data points (N) \n",
    "2. Subtract the mean from each datapoint. The differences are called deviations. \n",
    "3. Square the sum of $(x_i-\\mu)$\n",
    "4. Add all the squared deviations together\n",
    "5. Divide the sum of the squared deviations by the number of datapoints (N) to get the variance.\n",
    "6. Get the square root of the variance to get the population standard deviation ($\\sigma$)\n",
    "\n",
    "**Sample standard deviation:**\n",
    "\n",
    "$$\\bar{x}=\\sqrt\\frac{\\sum(x_i-\\bar{x})^2}{n-1}$$\n",
    "\n",
    "1. Calculate the mean ($\\bar{x}$) of all data points (n -1) \n",
    "2. Subtract the mean from each datapoint. The differences are called deviations. \n",
    "3. Square the sum of $(x_i-\\bar{x})$\n",
    "4. Add all the squared deviations together\n",
    "5. Divide the sum of the squared deviations by the number of datapoints (n-1) to get the variance.\n",
    "6. Get the square root of the variance to get the sample standard deviation ($\\sigma$)\n",
    "\n",
    "**Terminology**\n",
    "\n",
    "Population Standard Deviation (STDEV.P): a set of numbers that contains ALL members of a group (everybody in the population)\n",
    "\n",
    "Sample Standard Deviation (STDEV.S): a set that contains some members of a population [5]\n",
    "\n",
    "**When to use each one?**\n",
    "\n",
    "The population standard deviation would be used if: (1) you have the entire population (N) or (2) you have a sample of a larger population, but you are only interested in this sample and do not wish to generalize your findings to the population.\n",
    "You can use the sample standard deviation to estimate a population if you have a sample, but you wish to make a statement about the population standard deviation from which the sample is drawn. [6]\n",
    "\n",
    "**STDEV.P** - when you have data for the entire population or you have a sample of data but you only want the standard deviation for that sample. You do not need to extrapolate the data for the entire population. [8]\n",
    "\n",
    "**STDEV.S** - large sample and you want to approximate standard deviation for the entire population\n",
    "\n",
    "#### STDEV.P vs STDEV.S in Excel\n",
    "\n",
    "###### Image 1 - STDEV.P on Population\n",
    "<img src=\"images/stdevp-pop.PNG\" width=\"500\">\n",
    "\n",
    "###### Image 2 - STDEV.P on Sample\n",
    "<img src=\"images/stdevp-sample.PNG\" width=\"500\">\n",
    "\n",
    "###### Image 3 - STDEV.S on Sample\n",
    "<img src=\"images/stdevs-sample.PNG\" width=\"500\">\n",
    "\n",
    "It is clear from the above images that there is a difference in calculation between STDEV.P & STDEV.S. If you compare image 2 & image 3, both use the same data in their calculation but end up with a different result. As mentioned above, that is because STDEV.S utilises `n-1` and is an estimate of the population as a whole but STDEV.P is showing the exact standard deviation of the sample itself. It is not an estimate of the population. If you use STDEV.P on sample data to estimate a population, your result may be way off of the actual standard deviation depending on the data in the sample. \n",
    "\n",
    "STDEV.P - you calculate statistics for an entire population (mean, variance, etc.). The results are accurate because all data is available, it is not suitable for estimating. \n",
    "When you calculate statistics for a sample, results are estimates and therefore not as accurate. STDEV.S uses Bessel's correction which is an adjustment made to correct for bias that occurs when working with sample data. When working with a sample population, STDEV.S can provide a better estimation of the standard deviation. [8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy has a standard built in function to determine the standard deviation. It by default will use the population standard deviation unless modified. By using ddof = 1 you get an unbiased estimator of the variance of the population which will be equivilant to the sample standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population standard deviation using np.std:  6.681317235396026\n",
      "Population standard deviation using formula: 6.681317235396026\n",
      "\n",
      "\n",
      "Sample standard deviation using formula:     6.606057825965498\n"
     ]
    }
   ],
   "source": [
    "#manually generated data of no specific distibution\n",
    "# shows difference between calculations\n",
    "x = [1, 6, 7, 4, 8, 3, 19, 23, 5, 8, 16, 18, 20, 10, 11]\n",
    "\n",
    "# stdev.p on the population x using formula\n",
    "stdev_p = np.sqrt(np.sum(abs(x - np.mean(x))**2)/len(x))\n",
    "#built in std deviation function (default ddof =0) of a population x\n",
    "a = np.std(x)\n",
    "\n",
    "\n",
    "#stdev.s on the population x\n",
    "stdev_s = np.sqrt(np.sum(abs(x - np.mean(x))**2)/len(x)-1)\n",
    "\n",
    "\n",
    "print('Population standard deviation using np.std: ', a)\n",
    "print('Population standard deviation using formula:',stdev_p)\n",
    "print('\\n')\n",
    "print('Sample standard deviation using formula:    ',stdev_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random data for simulation\n",
    "# adapted from https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html#numpy.random.normal\n",
    "\n",
    "mean, std = 100, 5 # mean and standard deviation\n",
    "population = np.random.normal(mean, std, 1000) # generate population with normal distribution around mean at 100, std of 2. 1000 datapoints\n",
    "# print(population) to show the data in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create plot with above data\n",
    "# https://seaborn.pydata.org/generated/seaborn.distplot.html\n",
    "\n",
    "# adjust the size of the plot\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# create plot\n",
    "sns.distplot(population, color='y', bins=30)\n",
    "\n",
    "# set labels and title\n",
    "# show the plot\n",
    "plt.xlabel('Population', fontsize=15)\n",
    "plt.ylabel('Frequency', fontsize=15)\n",
    "plt.title('Population - Normal Distribution', fontsize = 15)\n",
    "plt.axvline(x=95, color='r', linestyle='--') #line to show -5 std\n",
    "plt.axvline(x=105, color='r', linestyle='--') #line to show +5 std\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population standard deviation (STDEV.P) = 5.000811\n"
     ]
    }
   ],
   "source": [
    "# use STDEV.P go get actual standard deviation of full population\n",
    "\n",
    "population_std = np.std(population)\n",
    "print(f'Population standard deviation (STDEV.P) = {population_std:.6f}')\n",
    "#print(population_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample standard deviation (STDEV.S) with 50 samples estimates population standard deviation to be = 5.597330\n",
      "Sample standard deviation (STDEV.S) with 100 samples estimates population standard deviation to be = 4.825158\n",
      "Sample standard deviation (STDEV.S) with 150 samples estimates population standard deviation to be = 5.404675\n",
      "Sample standard deviation (STDEV.S) with 250 samples estimates population standard deviation to be = 4.862191\n",
      "Sample standard deviation (STDEV.S) with 500 samples estimates population standard deviation to be = 5.080224\n",
      "Population standard deviation (STDEV.P) with 50 samples estimates population standard deviation to be = 5.541074\n",
      "Sample standard deviation (STDEV.S) with average of all samples estimates population standard deviation to be = 5.153916\n"
     ]
    }
   ],
   "source": [
    "# use STDEV.S to estimate standard deviation of the population\n",
    "\n",
    "# Create a sample data by using np.random.choice() function \n",
    "sample1 = 50\n",
    "sample2 = 100\n",
    "sample3 = 150\n",
    "sample4 = 250\n",
    "sample5 = 500\n",
    "\n",
    "#print(sample1_std) - shows 50 random samples from population\n",
    "#print(sample2_std) - shows 100 random samples from population\n",
    "#print(sample3_std) - shows 150 random samples from population\n",
    "#print(sample4_std) - shows 250 random samples from population\n",
    "#print(sample5_std) - shows 500 random samples from population\n",
    "\n",
    "sample1_std= np.random.choice(population, sample1)\n",
    "sample2_std= np.random.choice(population, sample2)\n",
    "sample3_std= np.random.choice(population, sample3)\n",
    "sample4_std= np.random.choice(population, sample4)\n",
    "sample5_std= np.random.choice(population, sample5)\n",
    "\n",
    "\n",
    "# calculate sample standard deviation by calling created previously variables\n",
    "stdev_s1 = np.std(sample1_std, ddof=1)\n",
    "stdev_s2 = np.std(sample2_std, ddof=1)\n",
    "stdev_s3 = np.std(sample3_std, ddof=1)\n",
    "stdev_s4 = np.std(sample4_std, ddof=1)\n",
    "stdev_s5 = np.std(sample5_std, ddof=1)\n",
    "population_std_s1 = np.std(sample1_std, ddof=0)\n",
    "avg_std = (stdev_s1+stdev_s2+stdev_s3+stdev_s4+stdev_s5)/5\n",
    "\n",
    "\n",
    "\n",
    "#print standard deviation for each sample\n",
    "print(f'Sample standard deviation (STDEV.S) with 50 samples estimates population standard deviation to be = {stdev_s1:.6f}')\n",
    "print(f'Sample standard deviation (STDEV.S) with 100 samples estimates population standard deviation to be = {stdev_s2:.6f}')\n",
    "print(f'Sample standard deviation (STDEV.S) with 150 samples estimates population standard deviation to be = {stdev_s3:.6f}')\n",
    "print(f'Sample standard deviation (STDEV.S) with 250 samples estimates population standard deviation to be = {stdev_s4:.6f}')\n",
    "print(f'Sample standard deviation (STDEV.S) with 500 samples estimates population standard deviation to be = {stdev_s5:.6f}')\n",
    "print(f'Population standard deviation (STDEV.P) with 50 samples estimates population standard deviation to be = {population_std_s1:.6f}')\n",
    "print(f'Sample standard deviation (STDEV.S) with average of all samples estimates population standard deviation to be = {avg_std:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why STDEV.S is better for estimating a population\n",
    "\n",
    "As can be seen from the cell above, there is variance in every answer. As the samle size increases, you should see an estimate closer to the actual population mean. That is because you obviosuly you have more datapoints from the population to aide in the estimate. The average of the 5 STDEV.S emtimates is also an interesting calculation because the more estimates that are completed of the population using STDEV.S, you will again have more real data. If you did hundreds or thousands of estimates of the population and looked at the average of them all, you would begin to see why `n-1` is used in sample deviation. If seen on a plot, you would notice that after each average, the estimate would become more accurate.\n",
    "\n",
    "STDEV.S is better for estimating a population. Depending on your sample data and sample size, if you use STDEV.P to estimate a population, your result could be way off from the actual population standard deviation. As per the above code, using STDEV.P to estimate the population is giving one of the worst estimates. All it is doing is giving the actual standard deviation for those 50 random points from the whole population. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "\n",
    "STDEV.P and STDEV.S are both functions in excel that perform standard deviation. STDEV.P is used for getting the standard deviation of a population while STDEV.S is used for estimating the standard deviation of a population. \n",
    "\n",
    "NumPy has the capability to work like the Excel functions STDEV.P and STDEV.S. it has a built in function called `numpy.std` which operates the same as STDEV.P. The function allows you to pass an arguement `ddof=1` which changes the standard deviation caluclation to the same as STDEV.S\n",
    "\n",
    "Using STDEV.S is a better option than STDEV.P for estimating a population but it will always be an estimate. STDEV.P results in a biased answer for estimating and STDEV.S will reduce that error. How much the error is reduced by depends on factors such as:  increasing the sample taken from the population or completing multiple sample standard deviations and averaging the results.\n",
    "\n",
    "STDEV.P is the more accurate calculation as it gives you the exact result but in real world situations it is not always feasible (and in alot of cases not possible) to use the full population to calculate and that is why STDEV.S (unbiased) is the more appropiate function for estimating a population. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "1. Wikipedia. Standard deviation - Wikipedia. [ONLINE] Available at: https://en.wikipedia.org/wiki/Standard_deviation. [Accessed 26 November 2020].\n",
    "2. Investopedia. Standard Deviation Definition. [ONLINE] Available at: https://www.investopedia.com/terms/s/standarddeviation.asp. [Accessed 26 November 2020].\n",
    "3. STDEV.S function - Office Support. 2020. STDEV.S function - Office Support. [ONLINE] Available at: https://support.microsoft.com/en-us/office/stdev-s-function-7d69cf97-0c1f-4acf-be27-f3e83904cc23. [Accessed 26 November 2020].\n",
    "4. STDEV.P function - Office Support. 2020. STDEV.P function - Office Support. [ONLINE] Available at: https://support.microsoft.com/en-us/office/stdev-p-function-6e917c05-31a0-496f-ade7-4f4e7462f285. [Accessed 26 November 2020].\n",
    "5. Eden Au. Why Sample Variance is Divided by n-1 | by Eden Au | Towards Data Science. [ONLINE] Available at: https://towardsdatascience.com/why-sample-variance-is-divided-by-n-1-89821b83ef6d. [Accessed 26 November 2020].\n",
    "6. Standard Deviation | How and when to use the Sample and Population Standard Deviation - A measure of spread | Laerd Statistics. Standard Deviation | How and when to use the Sample and Population Standard Deviation - A measure of spread | Laerd Statistics. [ONLINE] Available at: https://statistics.laerd.com/statistical-guides/measures-of-spread-standard-deviation.php. [Accessed 26 November 2020].\n",
    "7. Wikipedia. Bessel's correction - Wikipedia. [ONLINE] Available at: https://en.wikipedia.org/wiki/Bessel%27s_correction#:~:text=Firstly%2C%20while%20the%20sample%20variance,is%20downward%2C%20by%20Jensen's%20inequality.. [Accessed 26 November 2020].\n",
    "8. Excel formula: Standard deviation calculation | Exceljet. 2020. Excel formula: Standard deviation calculation | Exceljet. [ONLINE] Available at: https://exceljet.net/formula/standard-deviation-calculation. [Accessed 26 November 2020].\n",
    "9. https://www.khanacademy.org/math/statistics-probability/summarizing-quantitative-data/variance-standard-deviation-sample/a/population-and-sample-standard-deviation-review#:~:text=Standard%20deviation%20measures%20the%20spread%20of%20a%20data%20distribution.&text=If%20the%20data%20is%20being,n%2D1%20n%E2%88%921%20.\n",
    "10. numpy.std — NumPy v1.19 Manual. 2020. numpy.std — NumPy v1.19 Manual. [ONLINE] Available at: https://numpy.org/doc/stable/reference/generated/numpy.std.html#:~:text=The%20standard%20deviation%20is%20the,N%20%3D%20len(x)%20.. [Accessed 26 November 2020].\n",
    "11. GitHub. programming_DA_project_2019/numpy_tutorial.ipynb at master · kevindooley/programming_DA_project_2019 · GitHub. [ONLINE] Available at: https://github.com/kevindooley/programming_DA_project_2019/blob/master/numpy_tutorial.ipynb. [Accessed 26 November 2020]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Task 4 - K-means Clustering\n",
    "\n",
    "Use `scikit-learn`to apply k-means clustering to Fisher’s famous Iris data set. Explain how the code works and how accurate it might be, then explain how your model could be used to make predictions of species of iris.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction & Research\n",
    "\n",
    "##### Background on Iris Dataset\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper \"The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.\". The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimetres. The data set contains 150 observations of iris flowers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kmeans Clustering\n",
    "\n",
    "Clustering is a common exploratory data analysis technique used to get information about the structure of  data. It can be defined as the task of identifying subgroups in the data such that data points in the same subgroup (cluster) are very similar while data points in different clusters are very different. [1] A Cluster is a collection of data points aggregated together because of certain similarities. \n",
    "\n",
    "Clustering is known to be an unsupervised learning method that allows you to group a dataset based on similair characteristics, it can help you find useful structure among your data, group similar data together and discover underlying patterns. [2] Unsupervised learning basically means the algorithm looks for undetected patterns in an unlabelled data set with a minimum of human supervision.\n",
    "\n",
    "K-means is a common clustering algorithm of which its goal is to partition the data into such state that the total sum of squared distances between the points and their respective cluster centroid is minimised. [2]\n",
    "K-means is known as a centroid-based algorithm, or a distance-based algorithm, where we calculate the distances to assign a point to a cluster. A centroid is a location representing the center of a cluster. \n",
    "\n",
    "The K-means algorithm works iteratively to assign each data point to one of K groups based on the features that are provided. \n",
    "\n",
    "##### How it works?\n",
    "\n",
    "**Step 1.** \n",
    "The algorithm starts with determining the number of K clusters. K signifies the number of clusters that the algorithm will find in the dataset.It is very important to know the correct K. Unless K is already known (unlikely when using real world data), it will not always be clearly visible what K and can be quite difficult to determine what the correct value of K should be. One common way K can be estimated, is by using the elbow method and a parameter known as WCSS (Within Cluster Sum of Squares).Basically, select the value of K that causes the most significant decrease in the sum of squared distances, i.e the area where the elbow forms[3]\n",
    "***\n",
    "\n",
    "**Step 2.** \n",
    "Then the algorithm selects the number of centroids (starting points). These points can be within or outside the dataset but caution does have to be taken to avoid the initialisation trap. Once the initial centroids have initialised, each data point in the set is assigned to the closest cluster centroid. [4] \n",
    "As can be seen from image 1, 3 clusters were initialised and each datapoint has been accordingly assigned to its closest centroid. \n",
    "\n",
    "**Image 1.**\n",
    "<img src=\"images/cluster.PNG\" width=\"300\">\n",
    "Image Credit: [Healthcare.ai](https://healthcare.ai/step-step-k-means-clustering/)\n",
    "***\n",
    "\n",
    "**Step 3.** \n",
    "The next step is to recompute the centroids of newly formed clusters. All the points have been assigned based on which cluster center they were closest to. Next, the centroids are updated based on the points assigned to them. For instance, we can find the center mass of the blue cluster by summing over all the blue points and dividing by the total number of points, which is four here. And the resulted center mass C1’, represented by a blue diamond, is our new center for the blue cluster. Similarly, we can find the new centers C2’ and C3’ for the green and red clusters. [5]\n",
    "\n",
    "**Image 2.** \n",
    "<img src=\"images/cluster2.PNG\" width=\"300\">\n",
    "Image Credit: [Healthcare.ai](https://healthcare.ai/step-step-k-means-clustering/)\n",
    "***\n",
    "\n",
    "**Step 4.** \n",
    "The final step is to improve the clusters further with numeruous iterations of steps 2 and 3. Moving each centroid to the center of its cluster until the centroids stop moving, the K-means algorithm becomes converged. [6]\n",
    "\n",
    "***\n",
    "**Image 3. Summary depiction of K-means Process**\n",
    "<img src=\"images/kmeansum.PNG\" width=\"500\">\n",
    "Image Credit: [Kaggle](https://www.kaggle.com/shrutimechlearn/step-by-step-kmeans-explained-in-detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width         species\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# imported iris dataset csv file\n",
    "# prints out the data set\n",
    "\n",
    "df = pd.read_csv(\"irisdataset.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "x = df.iloc[:, [0, 1, 2, 3]].values #get out the values from the 4 attributes\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width      species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# prints out first out first 5 rows of dataset (default)\n",
    "# input any number to get that many rows displayed\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#species distribution throughout dataset\n",
    "print(df.groupby('species').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pair plot/scatterplot\n",
    "#markers - gives legend \n",
    "#hue - determines which column in the data frame should be used for colour encoding\n",
    "sns.pairplot(df, hue=\"species\", palette=\"husl\", markers=[\"o\", \"s\", \"D\"])\n",
    "\n",
    "#show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above give a very basic overview of what is contained in the dataset. We can see there are of 3 species: iris Setosa, iris-versicolor and iris virginica. There are 50 of each species contained in the dataset and the dataset looks at petal length/width and sepal length/width of each species. The pairplot above also seems to indicate the iris setosa appears to have different characteristics to iris versicolor and iris virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Elbow method to find number of clusters k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the elbow method to find the optimal number of clusters\n",
    "# adapted from https://www.kaggle.com/shrutimechlearn/step-by-step-kmeans-explained-in-detail\n",
    "\n",
    "wcss = []\n",
    "\n",
    "#loop though range\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "    kmeans.fit(x)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    \n",
    "plt.plot(range(1, 11), wcss, marker='x') # show clusters in range\n",
    "plt.title('The elbow method') # title\n",
    "plt.xlabel('Number of clusters') # xaxis label\n",
    "plt.ylabel('WCSS') #within cluster sum of squares\n",
    "plt.show() #print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a well known dataset, we already knew 3 was the optimum number of clusters. But as the elbow diagram demonstrates above, optimum clusters are where the elbow occurs. This is when the within cluster sum of squares (WCSS) doesn't decrease significantly with every iteration. 3 clusters falls within that category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean = datasets.load_iris() # load dataset from sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target and predictors\n",
    "x = kmean.data[:,]\n",
    "y = kmean.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean.data #returns values. same as above except using built in capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean.target # actual 3 clusters of species from the dataset\n",
    "# each number represents each species\n",
    "# the below is the true representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot values for sepal length(column 0) and width(column 1).\n",
    "\n",
    "plt.scatter(x[:,0], x[:,1], c=y) \n",
    "plt.xlabel('Sepal Length') \n",
    "plt.ylabel('Sepal Width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot values for petal length(column 2) and width(column 3).\n",
    "plt.scatter(x[:,2], x[:,3],c=y)\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Petal Width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans fitting/prediction\n",
    "# pre specify the clusters\n",
    "kmeans = KMeans(n_clusters = 3, random_state=0)\n",
    "KMmodel = kmeans.fit(x)\n",
    "KMmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify cluster centres\n",
    "# centre for each of the 4 attributes for each flower species\n",
    "cent = kmeans.cluster_centers_\n",
    "print(cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of the Kmean model\n",
    "#see labels of all datapoints\n",
    "# below is the predicted represenation of the data\n",
    "KMmodel.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html\n",
    "#this will tell us to which cluster does the data observations belong.\n",
    "# Plot the identified clusters and compare with the answers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,8))\n",
    "axes[0].scatter(x[:, 0], x[:, 1], c=y, cmap='viridis',edgecolor='k', marker='x')\n",
    "axes[1].scatter(x[:, 0], x[:, 1], c=KMmodel.labels_, cmap='viridis',edgecolor='k', marker='x')\n",
    "axes[0].set_xlabel('Sepal length')\n",
    "axes[0].set_ylabel('Sepal width')\n",
    "axes[1].set_xlabel('Sepal length')\n",
    "axes[1].set_ylabel('Sepal width')\n",
    "axes[0].set_title('Actual', fontsize=12)\n",
    "axes[1].set_title('Predicted', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#associate each flower type with label\n",
    "# setosa - 0\n",
    "# versicolor - 1\n",
    "# virginica - 2\n",
    "df['Cluster_label'] = pd.Series(kmean.target, index=df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the actual data vs the predicted model using a pandas crosstable\n",
    "pd.crosstab(kmean.target,KMmodel.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means fitting can be relatively accurate for predicting the data. As can be seen in the above results. The model correctly categorised the 50 setosa species and only incorrectly categorised 2 of the versicolor species. The model was less accurate for the virginica species as it incorrectly categorised 14. We already knew the the setosa flower had different characteristics to the other two species through the pairplot above and therefore, it was easier for the k-means model to predict the categories correctly. For the versicolor and virginica species in which they share common sepal and petal characteristics, it was more difficult for algorithm to correctly predict. It seems the k-means algorithm is more suited to data that is more widely spread out. It is important to note that k-means is not a classification tool and while you can validate the accuracy of it, this is not the purpose of k-means. It's purpose is to find a grouping of data which maximizes between-clusters distances, it does not use your labeling to train. For maximization of accuracy, the implementation of an actual fit classifier such as kNN would demonstrate better results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "1. Imad Dabbura. K-means Clustering: Algorithm, Applications, Evaluation Methods, and Drawbacks | by Imad Dabbura | Towards Data Science. [ONLINE] Available at: https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a.[Accessed 14 December 2020].\n",
    "2. Belen Sanchez. PREDICTING IRIS FLOWER SPECIES WITH K-MEANS CLUSTERING IN PYTHON | by Belen Sanchez | Medium. [ONLINE] Available at: https://medium.com/@belen.sanchez27/predicting-iris-flower-species-with-k-means-clustering-in-python-f6e46806aaee. \n",
    "3. Step by Step KMeans Explained in Detail | Kaggle. 2020. Step by Step KMeans Explained in Detail | Kaggle. [ONLINE] Available at: https://www.kaggle.com/shrutimechlearn/step-by-step-kmeans-explained-in-detail. [Accessed 17 December 2020].\n",
    "4. Analytics Vidhya. K Means Clustering | K Means Clustering Algorithm in Python. [ONLINE] Available at: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/. [Accessed 14 December 2020].\n",
    "5. healthcare.ai. Step by Step to K-Means Clustering - healthcare.ai. [ONLINE] Available at: https://healthcare.ai/step-step-k-means-clustering/. [Accessed 15 December 2020].\n",
    "6. F D. Clustering using K-means algorithm | by F D | Towards Data Science. [ONLINE] Available at: https://towardsdatascience.com/clustering-using-k-means-algorithm-81da00f156f6. [Accessed 16 December 2020].\n",
    "7. GitHub.pands-project/Learn.py at master · kevindooley/pands-project · GitHub. [ONLINE] Available at: https://github.com/kevindooley/pands-project/blob/master/Learn.py. [Accessed 16 December 2020].\n",
    "8. Stack Abuse. K-Means Clustering with Scikit-Learn. [ONLINE] Available at: https://stackabuse.com/k-means-clustering-with-scikit-learn/. [Accessed 27 December 2020].\n",
    "9. Stack Overflow. python - sklearn: calculating accuracy score of k-means on the test data set - Stack Overflow. [ONLINE] Available at: https://stackoverflow.com/questions/37842165/sklearn-calculating-accuracy-score-of-k-means-on-the-test-data-set. [Accessed 27 December 2020].\n",
    "10. https://www.youtube.com/watch?v=asW8tp1qiFQ\n",
    "11. Jake VanderPlas. In Depth: k-Means Clustering | Python Data Science Handbook. [ONLINE] Available at: https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html. [Accessed 27 December 2020]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
